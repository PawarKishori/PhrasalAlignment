Anusaaraka Task:
Goal of Anusaaraka is to create word aligned parallel corpora using following resourses:
1. Anusaaraka output
2. Statistical Machine Translation output.
3. Alignment of Parser output

-----------------------------------------------------------------------------------------------------
My Task:

My task focuses on 3rd point.
Which will lead to a good nth layer generation.
One of my goals is to automate the creation of Hindi Treebank using output of phrasal alignment tool.

When the automated and correct hindi treebank is being created it can be used in the following tasks:
1. Creation of Hindi Parser(either by graph based learning or something else)
2. Gold Treebank created from automation and some rules.
3. A system to create automated hindi treebank from english-hindi parallel corpora.

------------------------------------------------------------------------------------------------------
Algorithm for automation system:

1. Do projection of relations from english to hindi if and only if
   a. E-H translation is very close i.e. All words eng and hindi words are aligned properly. (Unaligned words ==0) (From the data statistically can I check this condition**)
   b. sentences without Conjunction relation (for time being)
   c. sentences without prepositional attachment (for time being)
   d. Parse given by stanford for english sentence is correct.
   
4. Rule Step and/or learning step
   Do analysis and find out the rule 
      if u can find out the rule then do 2.1:
	2.1.
	If the relation from UD-english are one-many write the rules forappropriate relation.
        (As per the discussion, we can write rules for following relations )
        a. acl
	b. appos
	c. nsubjpass
	   etc.
      else do 2.2:
	2.2.
        Collect the different (as many as u can) examples from the corpora and real time (from linguists), then put all the data in structured format the apply some learning technique (like GCNN or something*) and learn the rules from the data instead of learning the data (which many statistical and ml based techniques does)
2. One to one relation mapping from english to hindi
   a. nsubj
   b. nmod 
	etc.
   
3. If we have mapped relations(from mapped relation dictionary**) from one relation name(in english) to the relation name(in hindi) then map such relations.
   a. advmod (BI) -> dep
																																																		
5. Prepare dictionary for such alignments.
   That is why - isiliye

------------------------------------------------------------------------------------------------------------
Number of columns for observations of sentences

01. English sentence
02. Hindi Sentence
03. Sentence id in phrasal alignment tool
04. Algorithm Step 1 Satisfied? 
05. number of interchunk relations in english sentence (ignore intrachunk for timebeing)
06. number of interchunk relations in hindi sentence
07. number of exact mapped relations (algo step 4)
08. list of 7 (algo step 4)
09. number of relations (algo step 3)
10. list of relations (algo step 3)
11. number of relations (algo step 2)
12. list of relations (algo step 2)
13. Rules extracted for the relation (algo step 2.1)
14. Dictionary observations




** work on this point
-------------------------------------------------------------------------------------------------
Update: 2-Dec-2017 : Meeting with Chaitanya Sir and Soma mam.
My ultimate aim is to improve parsers output, both Hindi and English.
So I need to create a better hindi parser too.
How I can do that? - Using Alignment tool developed which uses bootstrapping.
Alignment tool needs output of hindi and english parser. English  parser performs better than hindi parser. So primarily I need to focus on hindi parser first.
Alignment tool needs hindi parser to parse hindi sentences. Till now I was using hindi rule based parser developed by Roja mam. It's latest version was giving multiple relations which I cant use in alignment tool, and it was not that efficient too. So we decided to use Irshad's parser (simple neural network - 90% accuracy claimed) https://bitbucket.org/iscnlp/ which was trained on Hindi Treebank.
hindi_irshad.txt is output of this NNparser ran on hindi_raw.txt
The parser gives output in UD dep relations as well as paninian dep relations.
Sir claim that Paninian dep relations of irshad and us differ at some places.
Todays task - checking the accuracy of irshad's hindi parser (manually, with sir's paninian concept) and checking whether we can use that hindi parser into alignment tool for further bootstrapping.
hindi_irshad.txt    => wrongly annotated dep relations
                    *  Discussion required

Command to run iscnlp parser:
To get the hindi dependency tags with universal dependency tagset:
isc-parser -i meet-18-8 -o meet-18-8.out.ud -u

To get the hindi dependency tags with  Paninian dependency tagset:
isc-parser -i meet-18-8 -o meet-18-8.out.panini


-------------------------------------------------------------------------------------------------
3-dec-2017
Gathering of interchunk and intrachunk paninian dependencies from Pruthwik, Dipti mam
------------------------------------------------------------------------------------------------- 
4-dec-2017 
Error checking of parser output according to guidelines provided.
-------------------------------------------------------------------------------------------------
6-dec-2017
code to convert parser output to convinient reading format
-------------------------------------------------------------------------------------------------7
7-dec-2017
Earlier I ran it on training data(might be not sure ), so need to run the parser on new test data. I am running it on Gyan-Nidhi_en_hi_anoop corpus (500 sentences)
Task: Divide output into set of 10 sentences, analyse 10 sentences each.
-------------------------------------------------------------------------------------------------7
8-dec-2017
The hindi parser output is not totally accurate but we can use it in Phrsal Alignment tool.
-------------------------------------------------------------------------------------------------7
9-dec-2017
Creation of (Dipti mam's) Paninian to (Anusaaraka's)Paninian mapping. And add one more layer to Phrasal alignment tool which will use Irshad's NN parser and show hindi parser output aligned with English.
---------------------------------------------------------------------------------------------------
11-dec-2017
 
 sh run.sh <phrase-table-en-hi> <phrase-table-hi-en> <corpus_name>
 sh run.sh phrases_en-hi  phrases_hi-en  physics
 sh run.sh gyan_nidhi_en_hi_wx gyan_nidhi_hi_en_wx gyan_nidhi

This command takes the phrase table of the corpus created by Phrasal tool and changes this phrase output into dictionary gdbm format.
The gdbm output(gyan_nidhi_en_hi_wx, gyan_nidhi_hi_en_wx) will be saved in /anusaaraka/miscellaneous/SMT/phrasal_alignment

To run Alignment tool on parallel corpus, input is parallel chunks of sentences given parallel corpus. These are obtained by training parallel corpus on a statistical tool - Phrsal tool. So on 30k gyan nidhi parallel sentences, Phrasal is ran and we got gyan_nidhi_en_hi_wx and gyan_nidhi_hi_en_wx. These are phrase tables we obtatined, which are stored in gyan_nighi folder 

sh run_alignment.sh e1 h1 gyan_nidhi
This command is used to run alignment tool on parallel corpus e1 and h1, which also uses gyan_nidhi dictionary (gdbm- created by above run.sh command)

After that we need to do compilation steps to run alignment data.

*****
Giving error

Debugging:
/anusaaraka$ git diff --namestatus
error: invalid option: --namestatus
master@kishori-ThinkCentre-E73:~/anusaaraka$ git diff --name-status
M       multifast-v1.4.2/src/phrasal_mwe/extract_hindi_key.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key-hi-en.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key.c

git checkout all these 3 files 
++ 
Did some changes in run_alignment.sh // which was not committed
******
After successfully running phrasal alignment output will be generated in following dir with filename_eng_slign.html file
firefox /home/master/anu_output/e1_eng_align.html 

The backend files of phrasal alignment will be in : 
cd /home/master/tmp_anu_dir/tmp/gyan_nidhi_e500_tmp/
-----------------------------------------------------------------------------------------------
12-dec
program to convert parser output into facts format(manju mam)
mapping of UD tagging, Enhanced UD tagging, Sukhada Paninian notation, Dipti Paninian Notation
---------------------------------------------------------------------------------------------
14- dec
Stanford dep(nsubj, nmod) -> Paninian dep by Sukhda(krIyA-to-saMbabXI,etc) => Done for old version of Stanford parser
Have to update stanford parser in anusaaraka, this will add/remove/change stanford dep to Enhanced stanford dep.
Then need to map extra relations into again Sukhada paninian dependency.
This will bring dependency representation of stanford to paninian dependency(Sukhada's) from english side.

Now I also need to map Dipti mam's paninian dependency(k1,k2,lwg_psp,etc) to Sukhada paninian dependency(kriyA-to-saMbanXI) which was given by hindi parser.

All these will lead to 
1. create a parse tree for english sentence by stanford parser, with sukhada's paninian relation.
2. create a parse tree for hindi sentence by irshad's neural network parser, with sukhada's paninian relation.
3. And Alignment tool will create a parse trees of english and hindi sentences with same paninian relation.
4. This will lead to development of  parallel treebank automatically using Alignment tool.
5. Note: 100% mapping of stanford dependency relations into paninian is not possible in one instance. So we need to do in as much as possible now. Then with bootstrapping this procedure will automatically map the relations with building corpus as much as we can.

============================
Observation and Analysis:
1goeswith : She came because she liked me.
stanford latest not giving the output.
2
The director is 65 years <--old : nmod:npmod
Enhanced dep giving ERROR: Failed to load collapsed_ccproc_dep data! Please contact the administrator.

3
I want students to go.
There was a kid playing in the garden.
I made him build the house.
I got the house built.

remaining observations and analysis is on drive
===========================================================================================
15-Jan-2018
Till now I got confused in various things, but now I have cleared following things and the obsrvations are as follows:

1. CoreNLP is whole pipeline where it does everything from POS, NER, Co-referencing, Parsing etc. Initially I was running whole CoreNLP, but I should have run only stanford parser.
2. After instalation of stanford parser I need to analyze the 2 dependency formats given by stanford parser
a) stanford dependencies - basic, collapsed, ccprocessed, collapsed tree, non-collapsed. 
b) universal dependencies - basic, enhanced, enhanced++

Bell, a company which is based in LA, makes and distributes computer products
1.basic
2.collapsed (grouping, graph)
3.ccprocessed (propogation => here we need to work more)
4. collapsed tree 
5. non-collapsed tree (basic+extra)

Similarly do observations for UD (basic, enhanced, enhanced++)
.....
.....

Create documentation of commands of all variation with options (-originalDependencies, -outputFormat, -outputFormatOptions), with default conditions and which command to use for which type of output.

U should know which output format from above outputs should be used to do necessary information extraction, which will be used by us in stnford-parser-english-anusaaraka-extension. U should be master in that.

The next task told by sir
Just like the analysis I am doing for stanford, I should also do it for following 3:
1. Parser which uses, MRS-DMRS structure
2. Stanford Parser
3. Syntaxnet used by DeepL (which is performing better than Microsoft and google (in Europian languages) due to attention-based model)

I need to do it from hindi parsing side too.

Then we have to take a sentence which will show all distinctions of all 3 parsers and there dependencies, and how we are dealing with all those and our extension work to all these parsers. This will give us english parsing very close to deep semantics. Which will help us to go in depth of semantics. So our goal is to make a platform for language independent deep semantics (this goal is similar to UD people, but to achieve they are going to shallow level, whereas we are going in depth of semantics.)

How this work is helpful for me?
So this is helpful for overall deep semantics independent of all languages
This is helpful to enhance Anusaaraka MT.
This is also helpful for Alignment tool which is my thesis topic. As parser improves my alignment tool gives me better result.

Deep learning (how to start)
Parsing expert (Needs :  Conscious, continous work. What I will learn :Breadth work, knowing of all parsers, Future Scope:)
Deep Semantics (Needs : Sanskrit knowledge)
CL

Write a proposal
-=============================================

How to run new 2017 stanford parser, its derived scripts etc is there in the following directory:
/home/kishori/anusaaraka/Parsers/stanford-parser/stanford-parser-full-2017-06-09/
You can see multiple outputs of that.
================================================================================================

18-may
Intigrating hindi parser
Irshad had created a new parser ... whose link is https://github.com/irshadbhat/nsdp-cs 
use this in phrasal alignment.

use this : mono_jm_parser.py
requirements: 
1.git is code
2. requiremwnts.txt
3. sudo pip install dynet

Download the pretrained models from: https://bitbucket.org/irshadbhat/nsdp-cs-models/src
extract the respective model using : bunzip2 *.bz2 

input file should be in wx format

Command to run the parser:
To get dependency parse with UD tagset
python mono_jm_parser.py --load /home/master/nsdp-cs/nsdp-cs-models/UD/HI/PARSER/hi-ud-parser --test meet-18-8 --output-file meet-18-8.out.v2.ud

To get dependency parse with Paninian tagset:
python mono_jm_parser.py --load /home/master/nsdp-cs/nsdp-cs-models/PANINI/HI/PARSER/hi-bist-parser --test meet-18-8 --output-fi
le meet-18-8.out.v2.panini
---------------------------------------------------------------
24-may

The hindi parser is making errors in POS tagging and i

------------------------------------------------------------------
26-may
Parsing analysis




---------------------------------------------------------------------
5 june
When parser is giving correct parser then utilise in alignment, if not improve respective parser=> write different parser module for it.:


1. Eng-Hin correct parse: the do alignment. Take information from parser
2. When English parser is correct then try to improve hindi parse and Hindi Parser.   ?How to decide which parser is correct?= We have to first see using which parser the nth layer  alignment is taking place. if it is using english parser and many left over words are there, then take hindi parser help and do alignment. So this problem can be solved to some(80%) extent using if else. And we can take help of human supervisor too, but that should be as minimal as possible. 
3. When Hindi parse is correct, improve english parse and Hindi Parser.
4. when both are incorrect, take help from each other and improve parse of each other.

meet 5:
कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की और ( मातृकुल ) से सम्बन्धित है और भारत कहने से उसके पिता की और ( पितृकुल ) से सम्बन्ध प्रकट होता है .


The above hindi sentence have typo => Ora, it should be ora. So such errors should be AUTOMATEDLY corrected using dictionary or something. As of now you do it manually.
कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की ओर ( मातृकुल ) से सम्बन्धित है और भारत कहने से उसके पिता की ओर ( पितृकुल ) से सम्बन्ध प्रकट होता है .

Analysis after meeting,
English dep parse is giving wrong parse, it is considering addresss as mainverb, but signifies is main verb in it.
Hindi dep parse is giving correct parse after modifying Ora to ora. 
Alignment was making error when same words occur twice in the sentences, it keeps doing mismatching. Such error can be resolved using scope of the clauses in the sentences.

In this sentence, consider English Dep, though it is wrong, the tree below 2 signifies concretely deciding boundaries of 2 small clauses i.e.
1. as Kounteya signifies his great blood relations from his mother's side
2. as Bharata signifies his greatness from his father's side.

Now when it comes to Hindi parse, which is correct(though sentence construction is   diffeent we can use for aligning the words in the scope)
Here the 2 clauses under 2 prakat hota he are:
1. कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की ओर ( मातृकुल ) से सम्बन्धित है 
2. और भारत कहने से उसके पिता की ओर ( पितृकुल ) से सम्बन्ध प्रकट होता है .

Once we identify 2 clause boundaries in english and hindi like this, Now we need to align English's 1st to hindi's 1st clause and same for 2.
We can do so by 
1. Konteya-कौंतेय alignment i.e by proper noun - proper noun alignment. 
2. mother - mata i.e. english-hindi dictionary, for a word, matching only once.
3. some other heuristics.

we can align words from hindi 1st clause in english's 1st clause. 
In this way, scope of the clauses can be decided by parser, and alignment will improve too much by this.

To get finer level alignment:
drop parenthesis content => to get closer parse.


kI vs ki -ask shastri

http://universaldependencies.org/treebanks/hi_hdtb/hi_hdtb-pos-ADP.html
kI:POS  ADP 8161: इस मंदिर का स्‍थापत्‍य अजंता की गुफाओं से प्रेरित है ।
ki: SCONJ

kI, here both are case
ki, here is mark
To address him as Kaunteya signifies his great blood relations from his mother's side; and to address him as Bhaarata signifies his greatness from his father's side.
Scope of the sentence can't be determined from hindi parse, as it is giving wrong parse: Here hindi parse is wrong mAtA kI Ora-> this Ora is wrongly POSed hence wrong parsing.


Rama said that he will eat from his mother's side.
1	Rama	Rama	NNP	PERSON	2	nsubj
2	said	say	VBD	O	0	ROOT
3	that	that	IN	O	6	mark
4	he	he	PRP	O	6	nsubj
5	will	will	MD	O	6	aux
6	eat	eat	VB	O	2	ccomp
7	from	from	IN	O	11	case
8	his	he	PRP$	O	9	nmod:poss
9	mother	mother	NN	O	11	nmod:poss
10	's	's	POS	O	9	case
11	side	side	NN	O	6	nmod
12	.	.	.	O	_	_

rAma ne kahA ki vaha usake mAwA kI ora se KAyegA. 
1       rAma    _       PROPN   _       _       3       nsubj   _       _
2       ne      _       ADP     _       _       1       case    _       _
3       kahA    _       VERB    _       _       0       root    _       _
4       ki      _       SCONJ   _       _       11      mark    _       _
5       vaha    _       PRON    _       _       11      nsubj   _       _
6       usake   _       PRON    _       _       7       nmod    _       _
7       mAwA    _       NOUN    _       _       11      obl     _       _
8       kI      _       ADP     _       _       7       case    _       _
9       ora     _       ADP     _       _       7       case    _       _
10      se      _       ADP     _       _       9       case    _       _
11      KAyegA  _       VERB    _       _       3       obj     _       _
12      .       _       PUNCT   _       _       3       punct   _       _
=======================================================================================================
11-6-18
1. Tell Manju mam to use tokenizer b4 parser
2. Add parser eng left over and hindi left over words in it.
3. 2.4 => why usaKi not aligned to his
4. 2.4 => Pira-BI => here relation is dep, which means hindi parser is not able to identify the relation, which should be defined. So this is work at UD dep vs paninian dep. and 'still' in english is 'Pira_BI' in hindi so there wont be any relation in english equivalent to dep(which is incorrect according to paninian)
5. 2.3 => appos in english and nmod in hindi. This should be mapped. So b4 that nmod should be nmod:r6, here r6 should be derived from case+kA information => write a clips rules into it.
6. MOST IMPORTANT: where the clips rule written, from where facts of parser output generated, how to debug?

==========================================================================================================
18-6-18

1. Sir told not to add tokenizer before parser for hindi. and manju mam resolved it internally using p1, p2, parse-word ids and by removing Punctuation.
   Sir says tokenizing punctuations will increase parse work, bcoz parser has to write a rule to dicide starting " and ending ".
   So my task is to find the cases where, I will show 2 o/ps tokenized o/p and not-tokenized o/p and show which will be better. Find a word "me whose relation was wrong by parser but if we tokenize it, it will improve the output.
 => Show such cases to sir 

2.When hindi parse and english parse are correct but still alignment is not able to resolve: 
 
  Find such cases of cop, aux, ...,who did something (jo-vo) cases. By statistics, show that 
	a) Query extraction: what relation is given by manual annotation => HDTB
	b) Query extraction: what relation is given by UD treebank => UD.conll
	c) Meeting with sir: What is paninian phenomenon
   while analysing all these, come to a conclusion and make the changes to clip rules/ write new clip rules.
   homework: h1) Theory: by seeing the english sentence I should understand what is correct english parse(according to UD english notations)
             h2) Theory: by seeing the hindi sentence I should understand what is correct hindi parse(according to UD hindi notations)	
	     h3) Clips: why there is difference between UD-english and UD-hindi ? Discuss with Dipti ma'am and then with sir.
		 Then we have to switch to Paninian relations, i.e. from english side map UD-english to Anu-panini mapping. And map UD-hindi relation to Anu-panini.
		 This mapping will envolve writing clips rules. => Clean the code,Prepare a parallel module by u, which is efficiently written.	
        There are long term and short term goals. Long term goals we have to meet for my thesis and for refined system
        There are short term goals/solutions. They are not that efficient compared to whole system, but have to do, to show working system to interns and people

3. When hindi parse is correct(? How to decide this=> if eng_parse else hindi_parse), align using scope
   When english parse is correct, align using scope


? Things to ask manju ma'am to make ur hands dirty:
	where the clips rule written, from where facts of parser output generated, how to debug?
	why she has written repetative code/rule? modify that
	


===========================================================================================================
obl discussion

Babur's Chinggisid lineage came from his mother's side
(ROOT
  (S
    (NP
      (NP (NNP Babur) (POS 's))
      (NNP Chinggisid) (NN lineage))
    (VP (VBD came)
      (PP (IN from)
        (NP
          (NP (PRP$ his) (NN mother) (POS 's))
          (NN side))))))

nmod:poss(lineage-4, Babur-1)
case(Babur-1, 's-2)
compound(lineage-4, Chinggisid-3)
nsubj(came-5, lineage-4)
root(ROOT-0, came-5)
case(side-10, from-6)
nmod:poss(mother-8, his-7)
nmod:poss(side-10, mother-8)
case(mother-8, 's-9)
nmod:from(came-5, side-10)

bAbara kA ciMgIsIxa vaMSa usake mAz kI Ora se AyA hE
1       bAbara  _       PROPN   _       _       4       nmod    _       _
2       kA      _       ADP     _       _       1       case    _       _
3       ciMgIsIxa       _       ADJ     _       _       4       amod    _       _
4       vaMSa   _       NOUN    _       _       10      nsubj   _       _
5       usake   _       PRON    _       _       6       nmod    _       _
6       mAz     _       NOUN    _       _       10      obl     _       _
7       kI      _       ADP     _       _       6       case    _       _
8       Ora     _       ADV     _       _       10      advmod  _       _
9       se      _       ADP     _       _       8       case    _       _
10      AyA     _       VERB    _       _       0       root    _       _
11      hE      _       AUX     _       _       10      aux     _       _


rAma ne ladake ko xeKA
1       rAma    _       PROPN   _       _       5       nsubj   _       _
2       ne      _       ADP     _       _       1       case    _       _
3       ladake  _       NOUN    _       _       5       obj     _       _
4       ko      _       ADP     _       _       3       case    _       _
5       xeKA    _       VERB    _       _       0       root    _       _


vaha xakRiNa ke Ora se AyA
1       vaha    _       PRON    _       _       6       nsubj   _       _
2       xakRiNa _       PROPN   _       _       4       nmod    _       _
3       ke      _       ADP     _       _       2       case    _       _
4       Ora     _       DET     _       _       6       obl     _       _
5       se      _       ADP     _       _       4       case    _       _
6       AyA     _       VERB    _       _       0       root    _       _
===============================================================================================
advcl vs advmod discussion
=================================================================================================
In the alignment task, if Hindi parser is doing wrong, then 

--------------------------------------------------------------------------------------------------------------
10-sept-2018
Write to do in this file for next day.
1. Telling sir the issue of why manual sentence is tokenized and not in parser. its in Anusaaraka_alignment.sh : line 82 and ask what to do on this? 
   => Told.
2. starting doing work in local git directory as well as github-forked. commiting changes of both. 
   => csnlp, Anusaaraka, alignment and run_log.sh 
3. Integrating tokenizer in parser as one module.
   => Done
4. Working for parser clause boundary.
   4.1 writing code to generate clause boundary facts
   => Algorithm for generation of facts from English and Hindi dependency parse
	Objective: Detection and extraction of intrachunk, interchunk, interclause clause boundary of a sentences
	VVIMP: Before using information from any tool(here parses) try to apply the heuristics on the data and then take help from tool outputs.

	This is to be done seperately. Now I am using only parser output to generate the facts and not any linguistic heuristic or any resource(eg vibhakti etc). So facts from parser will o/p are generated. Similarly, facts only from heuristics and dectionaries will be generated. We will start writing the rules for parser by taking help of these 2 facts which are same but coming from 2 different resource. Whereever there is discrepency in these 2 types of facts we need to rely on heuristics facts than parser one. In this way, we can tackle the problem when our tools are inaccurate. So our code will not break when the parser fails to perform(either parser error or parser unable to go in deep semantics) both drawbacks will be taken care by extra rules written in CLIPS whose basis is parser facts and heuristics facts.

	Algorithm A: Extract english clause facts
		Inputs: English Parse (in conll format)
		Output: facts
	==> Already Done
	As of now I am using facts from manju mam to extract parser information, I am not going to generate the facts again as there is not yet emergency arrived.
	
	Algorithm B: Extract hindi clause facts
	Inputs:  Hindi Parse (in conll format)
	
	==> Done

   4.2 Writing new algorithm for alignment task
	Till now I have debugged the Anusaaraka_alignment.sh Basically it is parsing hindi sentences, and preprocessing and fact generation from it. It  also does many other things(detailed: Old Anusaaraka Documentation in OneNote)
Tasks to be done:
	1. Code understanding: Why a script is called? What is its functionality? What is its input and what is its output? from Roja ma'am(documentation), either on call or directly meeting her face to face. 
	2. Fixing bugs by herself, OR write my own algorithm for the given task and new alignment task
		2.1 Code cleaning : What phrasal what is alignment what is browse
	3. Encorporate, things like Nandini's dictionary (either starting or ending)
	4. Encorporating NMT here.
	
   4.3 Start writing rules(for parser) which is one of the step in alignment task.
	Alignment layers have interdependency on each other in Manju mam's version. The solution over it is, we need to create each layer information and combine it into new Qth layer by applying customized rules.  
		
   4.4 Check the accuracy of the system with and without parser layer.
	500 sentences and their baseline accuracy will be done by Banasthali interns 2018-19(Monsoon batch)
	check the accuracy of alignment on new alignment algorithm vs old algorithm.
	
4.2 (By Sir) Roja and Manju mam are not directly involved to correct the errors or to understand the previous code. So the fast solution on this is creating my own alignment algorithm and which will be responsible for R layer, which will be my replacement of P, and replace Q layer by N.
Both these will be shown in spreadsheet. I am going to add Q and R layer in existing spreadsheet(which is either extracted directly from html or from dat files, archita's work). 
Do I need to think about R layer for Q? => No. R layer will be on top of Q layer, you need not to worry about it, but in meeting if some work occurs like integrating NMT (which has again next layers like S, T etc) o/p or integrating Nandani's dictionary, then I need to first create an algorithm to show R layer.

What is needed for Q layer? 
Input => Q layer will use eng and hindi parser output and dictionaries.
Output => Qth layer



Alignment % information is not that reliable measure to measure the alignment accuracy, so we have to involve human users to evaluate the accuracy.
Interns should get the files to evaluate the difference of alignment, with and without parser.
$$ To be done by 19th november

5. Deciding all the layers and seggregating the expected outputs for layers and sub-layers.
6. Modularizing the code.
6.1 Preparation of documentation.
7. Deciding the scope of my work
8. Start writing whatever work I done: i) Practical implementation writing ii) Paper type of writings
9. Talking to sir about my thesis boundary and one deep learning chapter
10. Clearing the factor of course work. So next semester should be the last one to finalize.
11. Writing papers in next semester.this sem
12. Apply for internships, fellowships etc.


Daily basis works:
1. Debug spell diff match error => miscellaneous/SMT/phrasal_alignment/alignment1.clp and /anusaaraka/miscellaneous/SMT/phrasal_alignment$ vim spellDifference.py
2. Debug number coming in Pth layer=> align word id with parser id from hindi side, just like did in english in run_module.bat, preprocessing module from stanford side. 
------------------------------------------------------
codes.git
This git repository contains all my codes irrespective of Anusaaraka hierarchy. Whatever code I write, I write it in this repo and the push in the same repo.
Alignment.git
This repo is the new repo created  for new Alignment repo, where Ayushi is collaborator. 
alignment.git
Old data and theory papers of alignment
clips_tutorial
clips notes tutorial
-------------------------------------------------------------
if total_hindi_verbs==total_eng_verbs=1 then align hindi verb under english verb

-----------------------------------------------------------
My tasks: 
1. clips rules for stanford parser, then
2. Integrating HPSG parser, syntaxnet in alignment
3. Reading Universal semnatic parser paper and explanaing to sir
4. Running models on iiit gpu


-----------------
Task for 9-jan:
Note on :
. Sd-lexicalize_info.dat = constituency parse
29. Ordered_constituents.dat
30. Node_category.dat
31. Ordered_constituents.dat
32. E_constituents_info.dat
28-32=> are for constituency parse facts

rule for substituting by manju mam's help

use pada_prawiniXI_info.dat to extract small introchunks information

Finally getting small chunks from english using dependency as well as constituency parse.

Getting small chunks from hindi dep parse.

bottom-to-top-align-chunks.clp => use intrachunks from eng and hindi sentence and with help of dictionaries align them.

E-chunkheadid-wordids.dat
H-chunkheadid-wordids.dat
dictionary-from-hindi-to-english.dat
dictionary-from-english-to-hindi.dat ?? ask sir


-------------------------------------
Clips rules for:
1. bottom-to-top chunk alignment (dictionary usage)
2. boundary-to-boundary alignment (dictionary usage)
3. edge-label(relations) postprocessing: semantically going into depth and bring every relation in UD english and UD hindi to anu paninian representation.
   Eg. xcomp in hindi parse is nothing but kriyamul in anu paninian dependency
   Eg. conj and cc: chnage the notation into anu panini in both eng and hindi.
   Eg. copula in hindi and copula in eng => converge them into samAnAXikarana 
4. mapping of one relation of english to another into hindi . 
	Eg. ccomp to obj(vakya karma)
5. Construction change mapping.

-----------------

