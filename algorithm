Anusaaraka Task:

Goal of Anusaaraka is to create word aligned parallel corpora using following resourses:
1. Anusaaraka output
2. Statistical Machine Translation output.
3. Alignment of Parser output

-----------------------------------------------------------------------------------------------------
My Task:

My task focuses on 3rd point.
Which will lead to a good nth layer generation.
One of my goals is to automate the creation of Hindi Treebank using output of phrasal alignment tool.

When the automated and correct hindi treebank is being created it can be used in the following tasks:
1. Creation of Hindi Parser(either by graph based learning or something else)
2. Gold Treebank created from automation and some rules.
3. A system to create automated hindi treebank from english-hindi parallel corpora.

------------------------------------------------------------------------------------------------------
Algorithm for automation system:

1. Do projection of relations from english to hindi if and only if
   a. E-H translation is very close i.e. All words eng and hindi words are aligned properly. (Unaligned words ==0) (From the data statistically can I check this condition**)
   b. sentences without Conjunction relation (for time being)
   c. sentences without prepositional attachment (for time being)
   d. Parse given by stanford for english sentence is correct.
   
4. Rule Step and/or learning step
   Do analysis and find out the rule 
      if u can find out the rule then do 2.1:
	2.1.
	If the relation from UD-english are one-many write the rules forappropriate relation.
        (As per the discussion, we can write rules for following relations )
        a. acl
	b. appos
	c. nsubjpass
	   etc.
      else do 2.2:
	2.2.
        Collect the different (as many as u can) examples from the corpora and real time (from linguists), then put all the data in structured format the apply some learning technique (like GCNN or something*) and learn the rules from the data instead of learning the data (which many statistical and ml based techniques does)
2. One to one relation mapping from english to hindi
   a. nsubj
   b. nmod 
	etc.
   
3. If we have mapped relations(from mapped relation dictionary**) from one relation name(in english) to the relation name(in hindi) then map such relations.
   a. advmod (BI) -> dep
																																																		
5. Prepare dictionary for such alignments.
   That is why - isiliye

------------------------------------------------------------------------------------------------------------
Number of columns for observations of sentences

01. English sentence
02. Hindi Sentence
03. Sentence id in phrasal alignment tool
04. Algorithm Step 1 Satisfied? 
05. number of interchunk relations in english sentence (ignore intrachunk for timebeing)
06. number of interchunk relations in hindi sentence
07. number of exact mapped relations (algo step 4)
08. list of 7 (algo step 4)
09. number of relations (algo step 3)
10. list of relations (algo step 3)
11. number of relations (algo step 2)
12. list of relations (algo step 2)
13. Rules extracted for the relation (algo step 2.1)
14. Dictionary observations




** work on this point
-------------------------------------------------------------------------------------------------
Update: 2-Dec-2017 : Meeting with Chaitanya Sir and Soma mam.
My ultimate aim is to improve parsers output, both Hindi and English.
So I need to create a better hindi parser too.
How I can do that? - Using Alignment tool developed which uses bootstrapping.
Alignment tool needs output of hindi and english parser. English  parser performs better than hindi parser. So primarily I need to focus on hindi parser first.
Alignment tool needs hindi parser to parse hindi sentences. Till now I was using hindi rule based parser developed by Roja mam. It's latest version was giving multiple relations which I cant use in alignment tool, and it was not that efficient too. So we decided to use Irshad's parser (simple neural network - 90% accuracy claimed) https://bitbucket.org/iscnlp/ which was trained on Hindi Treebank.
hindi_irshad.txt is output of this NNparser ran on hindi_raw.txt
The parser gives output in UD dep relations as well as paninian dep relations.
Sir claim that Paninian dep relations of irshad and us differ at some places.
Todays task - checking the accuracy of irshad's hindi parser (manually, with sir's paninian concept) and checking whether we can use that hindi parser into alignment tool for further bootstrapping.
hindi_irshad.txt    => wrongly annotated dep relations
                    *  Discussion required

-------------------------------------------------------------------------------------------------
3-dec-2017
Gathering of interchunk and intrachunk paninian dependencies from Pruthwik, Dipti mam
------------------------------------------------------------------------------------------------- 
4-dec-2017 
Error checking of parser output according to guidelines provided.
-------------------------------------------------------------------------------------------------
6-dec-2017
code to convert parser output to convinient reading format
-------------------------------------------------------------------------------------------------7
7-dec-2017
Earlier I ran it on training data(might be not sure ), so need to run the parser on new test data. I am running it on Gyan-Nidhi_en_hi_anoop corpus (500 sentences)
Task: Divide output into set of 10 sentences, analyse 10 sentences each.
-------------------------------------------------------------------------------------------------7
8-dec-2017
The hindi parser output is not totally accurate but we can use it in Phrsal Alignment tool.
-------------------------------------------------------------------------------------------------7
9-dec-2017
Creation of (Dipti mam's) Paninian to (Anusaaraka's)Paninian mapping. And add one more layer to Phrasal alignment tool which will use Irshad's NN parser and show hindi parser output aligned with English.
---------------------------------------------------------------------------------------------------
11-dec-2017
 
 sh run.sh <phrase-table-en-hi> <phrase-table-hi-en> <corpus_name>
 sh run.sh phrases_en-hi  phrases_hi-en  physics
 sh run.sh gyan_nidhi_en_hi_wx gyan_nidhi_hi_en_wx gyan_nidhi

This command takes the phrase table of the corpus created by Phrasal tool and changes this phrase output into dictionary gdbm format.
The gdbm output(gyan_nidhi_en_hi_wx, gyan_nidhi_hi_en_wx) will be saved in /anusaaraka/miscellaneous/SMT/phrasal_alignment

To run Alignment tool on parallel corpus, input is parallel chunks of sentences given parallel corpus. These are obtained by training parallel corpus on a statistical tool - Phrsal tool. So on 30k gyan nidhi parallel sentences, Phrasal is ran and we got gyan_nidhi_en_hi_wx and gyan_nidhi_hi_en_wx. These are phrase tables we obtatined, which are stored in gyan_nighi folder 

sh run_alignment.sh e1 h1 gyan_nidhi
This command is used to run alignment tool on parallel corpus e1 and h1, which also uses gyan_nidhi dictionary (gdbm- created by above run.sh command)

After that we need to do compilation steps to run alignment data.

*****
Giving error

Debugging:
/anusaaraka$ git diff --namestatus
error: invalid option: --namestatus
master@kishori-ThinkCentre-E73:~/anusaaraka$ git diff --name-status
M       multifast-v1.4.2/src/phrasal_mwe/extract_hindi_key.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key-hi-en.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key.c

git checkout all these 3 files 
++ 
Did some changes in run_alignment.sh // which was not committed
******
After successfully running phrasal alignment output will be generated in following dir with filename_eng_slign.html file
firefox /home/master/anu_output/e1_eng_align.html 

The backend files of phrasal alignment will be in : 
cd /home/master/tmp_anu_dir/tmp/gyan_nidhi_e500_tmp/
-----------------------------------------------------------------------------------------------
12-dec
program to convert parser output into facts format(manju mam)
mapping of UD tagging, Enhanced UD tagging, Sukhada Paninian notation, Dipti Paninian Notation
---------------------------------------------------------------------------------------------
14- dec
Stanford dep(nsubj, nmod) -> Paninian dep by Sukhda(krIyA-to-saMbabXI,etc) => Done for old version of Stanford parser
Have to update stanford parser in anusaaraka, this will add/remove/change stanford dep to Enhanced stanford dep.
Then need to map extra relations into again Sukhada paninian dependency.
This will bring dependency representation of stanford to paninian dependency(Sukhada's) from english side.

Now I also need to map Dipti mam's paninian dependency(k1,k2,lwg_psp,etc) to Sukhada paninian dependency(kriyA-to-saMbanXI) which was given by hindi parser.

All these will lead to 
1. create a parse tree for english sentence by stanford parser, with sukhada's paninian relation.
2. create a parse tree for hindi sentence by irshad's neural network parser, with sukhada's paninian relation.
3. And Alignment tool will create a parse trees of english and hindi sentences with same paninian relation.
4. This will lead to development of  parallel treebank automatically using Alignment tool.
5. Note: 100% mapping of stanford dependency relations into paninian is not possible in one instance. So we need to do in as much as possible now. Then with bootstrapping this procedure will automatically map the relations with building corpus as much as we can.




