Anusaaraka Task:

Goal of Anusaaraka is to create word aligned parallel corpora using following resourses:
1. Anusaaraka output
2. Statistical Machine Translation output.
3. Alignment of Parser output

-----------------------------------------------------------------------------------------------------
My Task:

My task focuses on 3rd point.
Which will lead to a good nth layer generation.
One of my goals is to automate the creation of Hindi Treebank using output of phrasal alignment tool.

When the automated and correct hindi treebank is being created it can be used in the following tasks:
1. Creation of Hindi Parser(either by graph based learning or something else)
2. Gold Treebank created from automation and some rules.
3. A system to create automated hindi treebank from english-hindi parallel corpora.

------------------------------------------------------------------------------------------------------
Algorithm for automation system:

1. Do projection of relations from english to hindi if and only if
   a. E-H translation is very close i.e. All words eng and hindi words are aligned properly. (Unaligned words ==0) (From the data statistically can I check this condition**)
   b. sentences without Conjunction relation (for time being)
   c. sentences without prepositional attachment (for time being)
   d. Parse given by stanford for english sentence is correct.
   
4. Rule Step and/or learning step
   Do analysis and find out the rule 
      if u can find out the rule then do 2.1:
	2.1.
	If the relation from UD-english are one-many write the rules forappropriate relation.
        (As per the discussion, we can write rules for following relations )
        a. acl
	b. appos
	c. nsubjpass
	   etc.
      else do 2.2:
	2.2.
        Collect the different (as many as u can) examples from the corpora and real time (from linguists), then put all the data in structured format the apply some learning technique (like GCNN or something*) and learn the rules from the data instead of learning the data (which many statistical and ml based techniques does)
2. One to one relation mapping from english to hindi
   a. nsubj
   b. nmod 
	etc.
   
3. If we have mapped relations(from mapped relation dictionary**) from one relation name(in english) to the relation name(in hindi) then map such relations.
   a. advmod (BI) -> dep
																																																		
5. Prepare dictionary for such alignments.
   That is why - isiliye

------------------------------------------------------------------------------------------------------------
Number of columns for observations of sentences

01. English sentence
02. Hindi Sentence
03. Sentence id in phrasal alignment tool
04. Algorithm Step 1 Satisfied? 
05. number of interchunk relations in english sentence (ignore intrachunk for timebeing)
06. number of interchunk relations in hindi sentence
07. number of exact mapped relations (algo step 4)
08. list of 7 (algo step 4)
09. number of relations (algo step 3)
10. list of relations (algo step 3)
11. number of relations (algo step 2)
12. list of relations (algo step 2)
13. Rules extracted for the relation (algo step 2.1)
14. Dictionary observations




** work on this point
-------------------------------------------------------------------------------------------------
Update: 2-Dec-2017 : Meeting with Chaitanya Sir and Soma mam.
My ultimate aim is to improve parsers output, both Hindi and English.
So I need to create a better hindi parser too.
How I can do that? - Using Alignment tool developed which uses bootstrapping.
Alignment tool needs output of hindi and english parser. English  parser performs better than hindi parser. So primarily I need to focus on hindi parser first.
Alignment tool needs hindi parser to parse hindi sentences. Till now I was using hindi rule based parser developed by Roja mam. It's latest version was giving multiple relations which I cant use in alignment tool, and it was not that efficient too. So we decided to use Irshad's parser (simple neural network - 90% accuracy claimed) https://bitbucket.org/iscnlp/ which was trained on Hindi Treebank.
hindi_irshad.txt is output of this NNparser ran on hindi_raw.txt
The parser gives output in UD dep relations as well as paninian dep relations.
Sir claim that Paninian dep relations of irshad and us differ at some places.
Todays task - checking the accuracy of irshad's hindi parser (manually, with sir's paninian concept) and checking whether we can use that hindi parser into alignment tool for further bootstrapping.
hindi_irshad.txt    => wrongly annotated dep relations
                    *  Discussion required

Command to run iscnlp parser:
To get the hindi dependency tags with universal dependency tagset:
isc-parser -i meet-18-8 -o meet-18-8.out.ud -u

To get the hindi dependency tags with  Paninian dependency tagset:
isc-parser -i meet-18-8 -o meet-18-8.out.panini


-------------------------------------------------------------------------------------------------
3-dec-2017
Gathering of interchunk and intrachunk paninian dependencies from Pruthwik, Dipti mam
------------------------------------------------------------------------------------------------- 
4-dec-2017 
Error checking of parser output according to guidelines provided.
-------------------------------------------------------------------------------------------------
6-dec-2017
code to convert parser output to convinient reading format
-------------------------------------------------------------------------------------------------7
7-dec-2017
Earlier I ran it on training data(might be not sure ), so need to run the parser on new test data. I am running it on Gyan-Nidhi_en_hi_anoop corpus (500 sentences)
Task: Divide output into set of 10 sentences, analyse 10 sentences each.
-------------------------------------------------------------------------------------------------7
8-dec-2017
The hindi parser output is not totally accurate but we can use it in Phrsal Alignment tool.
-------------------------------------------------------------------------------------------------7
9-dec-2017
Creation of (Dipti mam's) Paninian to (Anusaaraka's)Paninian mapping. And add one more layer to Phrasal alignment tool which will use Irshad's NN parser and show hindi parser output aligned with English.
---------------------------------------------------------------------------------------------------
11-dec-2017
 
 sh run.sh <phrase-table-en-hi> <phrase-table-hi-en> <corpus_name>
 sh run.sh phrases_en-hi  phrases_hi-en  physics
 sh run.sh gyan_nidhi_en_hi_wx gyan_nidhi_hi_en_wx gyan_nidhi

This command takes the phrase table of the corpus created by Phrasal tool and changes this phrase output into dictionary gdbm format.
The gdbm output(gyan_nidhi_en_hi_wx, gyan_nidhi_hi_en_wx) will be saved in /anusaaraka/miscellaneous/SMT/phrasal_alignment

To run Alignment tool on parallel corpus, input is parallel chunks of sentences given parallel corpus. These are obtained by training parallel corpus on a statistical tool - Phrsal tool. So on 30k gyan nidhi parallel sentences, Phrasal is ran and we got gyan_nidhi_en_hi_wx and gyan_nidhi_hi_en_wx. These are phrase tables we obtatined, which are stored in gyan_nighi folder 

sh run_alignment.sh e1 h1 gyan_nidhi
This command is used to run alignment tool on parallel corpus e1 and h1, which also uses gyan_nidhi dictionary (gdbm- created by above run.sh command)

After that we need to do compilation steps to run alignment data.

*****
Giving error

Debugging:
/anusaaraka$ git diff --namestatus
error: invalid option: --namestatus
master@kishori-ThinkCentre-E73:~/anusaaraka$ git diff --name-status
M       multifast-v1.4.2/src/phrasal_mwe/extract_hindi_key.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key-hi-en.c
M       multifast-v1.4.2/src/phrasal_mwe/extract_key.c

git checkout all these 3 files 
++ 
Did some changes in run_alignment.sh // which was not committed
******
After successfully running phrasal alignment output will be generated in following dir with filename_eng_slign.html file
firefox /home/master/anu_output/e1_eng_align.html 

The backend files of phrasal alignment will be in : 
cd /home/master/tmp_anu_dir/tmp/gyan_nidhi_e500_tmp/
-----------------------------------------------------------------------------------------------
12-dec
program to convert parser output into facts format(manju mam)
mapping of UD tagging, Enhanced UD tagging, Sukhada Paninian notation, Dipti Paninian Notation
---------------------------------------------------------------------------------------------
14- dec
Stanford dep(nsubj, nmod) -> Paninian dep by Sukhda(krIyA-to-saMbabXI,etc) => Done for old version of Stanford parser
Have to update stanford parser in anusaaraka, this will add/remove/change stanford dep to Enhanced stanford dep.
Then need to map extra relations into again Sukhada paninian dependency.
This will bring dependency representation of stanford to paninian dependency(Sukhada's) from english side.

Now I also need to map Dipti mam's paninian dependency(k1,k2,lwg_psp,etc) to Sukhada paninian dependency(kriyA-to-saMbanXI) which was given by hindi parser.

All these will lead to 
1. create a parse tree for english sentence by stanford parser, with sukhada's paninian relation.
2. create a parse tree for hindi sentence by irshad's neural network parser, with sukhada's paninian relation.
3. And Alignment tool will create a parse trees of english and hindi sentences with same paninian relation.
4. This will lead to development of  parallel treebank automatically using Alignment tool.
5. Note: 100% mapping of stanford dependency relations into paninian is not possible in one instance. So we need to do in as much as possible now. Then with bootstrapping this procedure will automatically map the relations with building corpus as much as we can.

============================
Observation and Analysis:
1goeswith : She came because she liked me.
stanford latest not giving the output.
2
The director is 65 years <--old : nmod:npmod
Enhanced dep giving ERROR: Failed to load collapsed_ccproc_dep data! Please contact the administrator.

3
I want students to go.
There was a kid playing in the garden.
I made him build the house.
I got the house built.

remaining observations and analysis is on drive
===========================================================================================
15-Jan-2018
Till now I got confused in various things, but now I have cleared following things and the obsrvations are as follows:

1. CoreNLP is whole pipeline where it does everything from POS, NER, Co-referencing, Parsing etc. Initially I was running whole CoreNLP, but I should have run only stanford parser.
2. After instalation of stanford parser I need to analyze the 2 dependency formats given by stanford parser
a) stanford dependencies - basic, collapsed, ccprocessed, collapsed tree, non-collapsed. 
b) universal dependencies - basic, enhanced, enhanced++

Bell, a company which is based in LA, makes and distributes computer products
1.basic
2.collapsed (grouping, graph)
3.ccprocessed (propogation => here we need to work more)
4. collapsed tree 
5. non-collapsed tree (basic+extra)

Similarly do observations for UD (basic, enhanced, enhanced++)
.....
.....

Create documentation of commands of all variation with options (-originalDependencies, -outputFormat, -outputFormatOptions), with default conditions and which command to use for which type of output.

U should know which output format from above outputs should be used to do necessary information extraction, which will be used by us in stnford-parser-english-anusaaraka-extension. U should be master in that.

The next task told by sir
Just like the analysis I am doing for stanford, I should also do it for following 3:
1. Parser which uses, MRS-DMRS structure
2. Stanford Parser
3. Syntaxnet used by DeepL (which is performing better than Microsoft and google (in Europian languages) due to attention-based model)

I need to do it from hindi parsing side too.

Then we have to take a sentence which will show all distinctions of all 3 parsers and there dependencies, and how we are dealing with all those and our extension work to all these parsers. This will give us english parsing very close to deep semantics. Which will help us to go in depth of semantics. So our goal is to make a platform for language independent deep semantics (this goal is similar to UD people, but to achieve they are going to shallow level, whereas we are going in depth of semantics.)

How this work is helpful for me?
So this is helpful for overall deep semantics independent of all languages
This is helpful to enhance Anusaaraka MT.
This is also helpful for Alignment tool which is my thesis topic. As parser improves my alignment tool gives me better result.

Deep learning (how to start)
Parsing expert (Needs :  Conscious, continous work. What I will learn :Breadth work, knowing of all parsers, Future Scope:)
Deep Semantics (Needs : Sanskrit knowledge)
CL

Write a proposal
-=============================================

How to run new 2017 stanford parser, its derived scripts etc is there in the following directory:
/home/kishori/anusaaraka/Parsers/stanford-parser/stanford-parser-full-2017-06-09/
You can see multiple outputs of that.
================================================================================================

18-may
Intigrating hindi parser
Irshad had created a new parser ... whose link is https://github.com/irshadbhat/nsdp-cs 
use this in phrasal alignment.

use this : mono_jm_parser.py
requirements: 
1.git is code
2. requiremwnts.txt
3. sudo pip install dynet

Download the pretrained models from: https://bitbucket.org/irshadbhat/nsdp-cs-models/src
extract the respective model using : bunzip2 *.bz2 

input file should be in wx format

Command to run the parser:
To get dependency parse with UD tagset
python mono_jm_parser.py --load /home/master/nsdp-cs/nsdp-cs-models/UD/HI/PARSER/hi-ud-parser --test meet-18-8 --output-file meet-18-8.out.v2.ud

To get dependency parse with Paninian tagset:
python mono_jm_parser.py --load /home/master/nsdp-cs/nsdp-cs-models/PANINI/HI/PARSER/hi-bist-parser --test meet-18-8 --output-fi
le meet-18-8.out.v2.panini
---------------------------------------------------------------
24-may

The hindi parser is making errors in POS tagging and i

------------------------------------------------------------------
26-may
Parsing analysis




---------------------------------------------------------------------
5 june
When parser is giving correct parser then utilise in alignment, if not improve respective parser=> write different parser module for it.:


1. Eng-Hin correct parse: the do alignment. Take information from parser
2. When English parser is correct then try to improve hindi parse and Hindi Parser.
3. When Hindi parse is correct, improve english parse and Hindi Parser.
4. when both are incorrect, take help from each other and improve parse of each other.

meet 5:
कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की और ( मातृकुल ) से सम्बन्धित है और भारत कहने से उसके पिता की और ( पितृकुल ) से सम्बन्ध प्रकट होता है .


The above hindi sentence have typo => Ora, it should be ora. So such errors should be AUTOMATEDLY corrected using dictionary or something. As of now you do it manually.
कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की ओर ( मातृकुल ) से सम्बन्धित है और भारत कहने से उसके पिता की ओर ( पितृकुल ) से सम्बन्ध प्रकट होता है .

Analysis after meeting,
English dep parse is giving wrong parse, it is considering addresss as mainverb, but signifies is main verb in it.
Hindi dep parse is giving correct parse after modifying Ora to ora. 
Alignment was making error when same words occur twice in the sentences, it keeps doing mismatching. Such error can be resolved using scope of the clauses in the sentences.

In this sentence, consider English Dep, though it is wrong, the tree below 2 signifies concretely deciding boundaries of 2 small clauses i.e.
1. as Kounteya signifies his great blood relations from his mother's side
2. as Bharata signifies his greatness from his father's side.

Now when it comes to Hindi parse, which is correct(though sentence construction is   diffeent we can use for aligning the words in the scope)
Here the 2 clauses under 2 prakat hota he are:
1. कौंतेय कहकर सम्बोधित करने से यह प्रकट होता है कि वह अपनी माता की ओर ( मातृकुल ) से सम्बन्धित है 
2. और भारत कहने से उसके पिता की ओर ( पितृकुल ) से सम्बन्ध प्रकट होता है .

Once we identify 2 clause boundaries in english and hindi like this, Now we need to align English's 1st to hindi's 1st clause and same for 2.
We can do so by 
1. Konteya-कौंतेय alignment i.e by proper noun - proper noun alignment. 
2. mother - mata i.e. english-hindi dictionary, for a word, matching only once.
3. some other heuristics.

we can align words from hindi 1st clause in english's 1st clause. 
In this way, scope of the clauses can be decided by parser, and alignment will improve too much by this.

To get finer level alignment:
drop parenthesis content => to get closer parse.


kI vs ki -ask shastri

http://universaldependencies.org/treebanks/hi_hdtb/hi_hdtb-pos-ADP.html
kI:POS  ADP 8161: इस मंदिर का स्‍थापत्‍य अजंता की गुफाओं से प्रेरित है ।
ki: SCONJ

kI, here both are case
ki, here is mark
To address him as Kaunteya signifies his great blood relations from his mother's side; and to address him as Bhaarata signifies his greatness from his father's side.
Scope of the sentence can't be determined from hindi parse, as it is giving wrong parse: Here hindi parse is wrong mAtA kI Ora-> this Ora is wrongly POSed hence wrong parsing.


Rama said that he will eat from his mother's side.
1	Rama	Rama	NNP	PERSON	2	nsubj
2	said	say	VBD	O	0	ROOT
3	that	that	IN	O	6	mark
4	he	he	PRP	O	6	nsubj
5	will	will	MD	O	6	aux
6	eat	eat	VB	O	2	ccomp
7	from	from	IN	O	11	case
8	his	he	PRP$	O	9	nmod:poss
9	mother	mother	NN	O	11	nmod:poss
10	's	's	POS	O	9	case
11	side	side	NN	O	6	nmod
12	.	.	.	O	_	_

rAma ne kahA ki vaha usake mAwA kI ora se KAyegA. 
1       rAma    _       PROPN   _       _       3       nsubj   _       _
2       ne      _       ADP     _       _       1       case    _       _
3       kahA    _       VERB    _       _       0       root    _       _
4       ki      _       SCONJ   _       _       11      mark    _       _
5       vaha    _       PRON    _       _       11      nsubj   _       _
6       usake   _       PRON    _       _       7       nmod    _       _
7       mAwA    _       NOUN    _       _       11      obl     _       _
8       kI      _       ADP     _       _       7       case    _       _
9       ora     _       ADP     _       _       7       case    _       _
10      se      _       ADP     _       _       9       case    _       _
11      KAyegA  _       VERB    _       _       3       obj     _       _
12      .       _       PUNCT   _       _       3       punct   _       _
=======================================================================================================
11-6-18
1. Tell Manju mam to use tokenizer b4 parser
2. Add parser eng left over and hindi left over words in it.
3. 2.4 => why usaKi not aligned to his
4. 2.4 => Pira-BI => here relation is dep, which means hindi parser is not able to identify the relation, which should be defined. So this is work at UD dep vs paninian dep. and 'still' in english is 'Pira_BI' in hindi so there wont be any relation in english equivalent to dep(which is incorrect according to paninian)
5. 2.3 => appos in english and nmod in hindi. This should be mapped. So b4 that nmod should be nmod:r6, here r6 should be derived from case+kA information => write a clips rules into it.
6. MOST IMPORTANT: where the clips rule written, from where facts of parser output generated, how to debug?

